

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=&#34;auto&#34;>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" type="image/png" href="https://gitee.com/cher112/image/raw/master/img/favicon.png# 网站标签页的 icon">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
    <meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="Zhihao Chen">
  <meta name="keywords" content="">
  <title>LSTM -Pytorch实现&amp;解构 - 陈之的鱼塘</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/github-gist.min.css" />
    
  

  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.3.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>My Nest</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                主页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                目录
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-link-fill"></i>
                友链
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" href="javascript:">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner intro-2" id="background" parallax=true
         style="background: url('https://www-1259766423.cos.ap-beijing-fsi.myqcloud.com/PicGo/意大利风情 (1).jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container page-header text-center fade-in-up">
            <span class="h2" id="subtitle">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2020-08-04 20:33" pubdate>
        August 4, 2020 pm
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      1.4k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      18
       分钟
    </span>
  

  
  
    
      <!-- LeanCloud 统计文章PV -->
      <span id="leancloud-post-views-container" class="post-meta" style="display: none">
        <i class="iconfont icon-eye" aria-hidden="true"></i>
        <span id="leancloud-post-views"></span> 次
      </span>
    
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto" id="post">
            <!-- SEO header -->
            <h1 style="display: none">LSTM -Pytorch实现&amp;解构</h1>
            
            <div class="markdown-body" id="post-body">
              <blockquote>
<p>部分源码和思路来源于 《Dive-into-DL-PyTorch》，很好的一本进阶书籍，推荐学习！</p>
</blockquote>
<p>本文适合对pytorch.nn，python-generator有一定基础的人观看，若对DL感兴趣想入门的朋友，推荐去看李宏毅2020的网课。</p>
<h1 id="LSTM介绍"><a href="#LSTM介绍" class="headerlink" title="LSTM介绍"></a>LSTM介绍</h1><p>LSTM 中引入了3个门，即输入门（input gate）、遗忘门（forget gate）和输出门（output gate），以及与隐藏状态形状相同的记忆细胞（某些文献把记忆细胞当成一种特殊的隐藏状态），从而记录额外的信息。<br>下图是一层lstm的图示，很好的展示了lstm的“记忆”过程：<br><img src="https://www-1259766423.cos.ap-beijing-fsi.myqcloud.com/PicGo/1.png" srcset="/img/loading.gif" alt=""></p>
<p>本次模型目标为：</p>
<ul>
<li>记忆周杰伦的歌词习惯</li>
<li>给出一个歌词集里出现过的字，输出下一个字，迭代50次生成一句歌词，同时预设歌词开头为”分开”</li>
</ul>
<h1 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h1><p>数据介绍：运用的周杰伦歌词集的text。因lyric数据具有很强的时序性，因此用lstm。同时为了突出时序，在小批量训练时我们用 *<em>相邻采样 *</em>而非一般的随机采样，后面会有介绍。</p>
<h2 id="标注"><a href="#标注" class="headerlink" title="标注"></a>标注</h2><ul>
<li>读取某文本的前10000个字符，需要将字符转码为独热编码</li>
<li>独热编码前，需要对每种字符进行”编号”，这里用了python的set和enumerate来生成不重复序列对象作为字典标识char</li>
<li>用字典(char_to_idx)来对每个char标注，再以字典进行独热编码，作为训练数据<pre><code class="hljs python"><span class="hljs-comment"># 设定学习所需的基本参数，后面会详细解释</span>
vocab_size: <span class="hljs-number">1027</span> —— 就是<span class="hljs-built_in">len</span>(char_to_idx)
num_input &amp; num_output:<span class="hljs-number">1027</span>, num_hidden: <span class="hljs-number">256</span> <span class="hljs-comment"># 规定LSTM的基本参数</span>
num_epochs, num_steps, batch_size, lr, clipping_theta = <span class="hljs-number">160</span>, <span class="hljs-number">35</span>, <span class="hljs-number">32</span>, <span class="hljs-number">1e2</span>, <span class="hljs-number">1e-2</span>
<span class="hljs-comment"># 对read的字符进行处理</span>
corpus_chars = corpus_chars.replace(<span class="hljs-string">&#x27;\n&#x27;</span>, <span class="hljs-string">&#x27; &#x27;</span>).replace(<span class="hljs-string">&#x27;\r&#x27;</span>, <span class="hljs-string">&#x27; &#x27;</span>)
corpus_chars = corpus_chars[<span class="hljs-number">0</span>:<span class="hljs-number">10000</span>]
idx_to_char = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(corpus_chars))
char_to_idx = <span class="hljs-built_in">dict</span>([(char, i) <span class="hljs-keyword">for</span> i, char <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(idx_to_char)]) <span class="hljs-comment"># 列表解析，后面将多次用到</span>
vocab_size = <span class="hljs-built_in">len</span>(char_to_idx)
corpus_indices = [char_to_idx[char] <span class="hljs-keyword">for</span> char <span class="hljs-keyword">in</span> corpus_chars]

<span class="hljs-comment"># one-hot步骤忽略，比较简单</span></code></pre>
<h2 id="生成器构造"><a href="#生成器构造" class="headerlink" title="生成器构造"></a>生成器构造</h2>如果想要自定义每次迭代时的过程，我们需要使用生成器</li>
</ul>
<h3 id="生成迭代对象"><a href="#生成迭代对象" class="headerlink" title="生成迭代对象"></a>生成迭代对象</h3><h4 id="相邻取样"><a href="#相邻取样" class="headerlink" title="相邻取样"></a>相邻取样</h4><blockquote>
<p>引自D2L原文</p>
</blockquote>
<p>令相邻的两个随机小批量在原始序列上的位置相毗邻。这时候，我们就可以用一个小批量最终时间步的隐藏状态来初始化下一个小批量的隐藏状态，从而使下一个小批量的输出也取决于当前小批量的输入，并如此循环下去。这对实现循环神经网络造成了两方面影响：一方面， 在训练模型时，我们只需在每一个迭代周期开始时初始化隐藏状态；另一方面，当多个相邻小批量通过传递隐藏状态串联起来时，模型参数的梯度计算将依赖所有串联起来的小批量序列。同一迭代周期中，随着迭代次数的增加，梯度的计算开销会越来越大。 为了使模型参数的梯度计算只依赖一次迭代读取的小批量序列，我们可以在每次读取小批量前将隐藏状态从计算图中分离出来。</p>
<pre><code class="hljs python"><span class="hljs-comment"># 生成迭代对象</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">data_iter_consecutive</span>(<span class="hljs-params">corpus_indices, batch_size, num_steps, device=<span class="hljs-literal">None</span></span>):</span>
    <span class="hljs-keyword">if</span> device <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:
        device = torch.device(<span class="hljs-string">&#x27;cuda&#x27;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;cpu&#x27;</span>) <span class="hljs-comment"># 深度学习计算量较大，推荐用cuda</span>
    corpus_indices = torch.tensor(corpus_indices, dtype=torch.float32, device=device)
    data_len = <span class="hljs-built_in">len</span>(corpus_indices)
    batch_len = data_len // batch_size
    indices = corpus_indices[<span class="hljs-number">0</span>: batch_size*batch_len].view(batch_size, batch_len)
    epoch_size = (batch_len - <span class="hljs-number">1</span>) // num_steps
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epoch_size):
        i = i * num_steps
        X = indices[:, i: i + num_steps]
        Y = indices[:, i + <span class="hljs-number">1</span>: i + num_steps + <span class="hljs-number">1</span>]
        <span class="hljs-keyword">yield</span> X, Y</code></pre>
<p>这里可视化一下相邻取样的逻辑<br><img src="https://www-1259766423.cos.ap-beijing-fsi.myqcloud.com/PicGo/2.png" srcset="/img/loading.gif" alt=""></p>
<h1 id="搭建模型"><a href="#搭建模型" class="headerlink" title="搭建模型"></a>搭建模型</h1><p>这里我们搭建一个 input_size = 1027, num_hidden = 256, output_size =1027， 一层lstm+一层全连接层的模型</p>
<pre><code class="hljs python">lstm_layer = nn.LSTM(input_size=vocab_size, hidden_size=num_hiddens)

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">RNNModel</span>(<span class="hljs-params">nn.Module</span>):</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, rnn_layer, vocab_size</span>):</span>
        <span class="hljs-built_in">super</span>(RNNModel, self).__init__()
        self.rnn = rnn_layer
        self.hidden_size = rnn_layer.hidden_size * (<span class="hljs-number">2</span> <span class="hljs-keyword">if</span> rnn_layer.bidirectional <span class="hljs-keyword">else</span> <span class="hljs-number">1</span>) 
        self.vocab_size = vocab_size
        self.dense = nn.Linear(self.hidden_size, vocab_size)
        self.state = <span class="hljs-literal">None</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, inputs, state</span>):</span> <span class="hljs-comment"># inputs: (batch, seq_len)</span>
        <span class="hljs-comment"># 获取one-hot向量表示</span>
        X = to_onehot(inputs, self.vocab_size) <span class="hljs-comment"># X是个list</span>
        Y, self.state = self.rnn(torch.stack(X), state)
        <span class="hljs-comment"># 全连接层会首先将Y的形状变成(num_steps * batch_size, num_hiddens)，它的输出</span>
        <span class="hljs-comment"># 形状为(num_steps * batch_size, vocab_size)</span>
        output = self.dense(Y.view(-<span class="hljs-number">1</span>, Y.shape[-<span class="hljs-number">1</span>]))
        <span class="hljs-keyword">return</span> output, self.state
    
model = RNNModel(lstm_layer)</code></pre>
<p>损失函数为交叉熵，小批量梯度下降的优化器为Adam，学习率见上，忽略。</p>
<pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train_and_predict_rnn_pytorch</span>(<span class="hljs-params">model, num_hiddens, vocab_size, device,</span></span>
<span class="hljs-function"><span class="hljs-params">                                corpus_indices, idx_to_char, char_to_idx,</span></span>
<span class="hljs-function"><span class="hljs-params">                                num_epochs, num_steps, lr, clipping_theta,</span></span>
<span class="hljs-function"><span class="hljs-params">                                batch_size, pred_period, pred_len, prefixes</span>):</span>
    loss = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    model.to(device)
    state = <span class="hljs-literal">None</span>
    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):
        l_sum, n, start = <span class="hljs-number">0.0</span>, <span class="hljs-number">0</span>, time.time()
        data_iter = data_iter_consecutive(corpus_indices, batch_size, num_steps, device) <span class="hljs-comment"># 相邻采样</span>
        <span class="hljs-keyword">for</span> X, Y <span class="hljs-keyword">in</span> data_iter:
            <span class="hljs-keyword">if</span> state <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:
                <span class="hljs-comment"># 使用detach函数从计算图分离隐藏状态, 这是为了</span>
                <span class="hljs-comment"># 使模型参数的梯度计算只依赖一次迭代读取的小批量序列(防止梯度计算开销太大)</span>
                <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span> (state, <span class="hljs-built_in">tuple</span>): <span class="hljs-comment"># LSTM, state:(h, c)  </span>
                    state = (state[<span class="hljs-number">0</span>].detach(), state[<span class="hljs-number">1</span>].detach())
                <span class="hljs-keyword">else</span>:   
                    state = state.detach()
    
            (output, state) = model(X, state) <span class="hljs-comment"># output: 形状为(num_steps * batch_size, vocab_size)</span>
            
            <span class="hljs-comment"># Y的形状是(batch_size, num_steps)，转置后再变成长度为</span>
            <span class="hljs-comment"># batch * num_steps 的向量，这样跟输出的行一一对应</span>
            y = torch.transpose(Y, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>).contiguous().view(-<span class="hljs-number">1</span>)
            l = loss(output, y.long())
            
            optimizer.zero_grad()
            l.backward()
            <span class="hljs-comment"># 梯度裁剪</span>
            grad_clipping(model.parameters(), clipping_theta, device)
            optimizer.step()
            l_sum += l.item() * y.shape[<span class="hljs-number">0</span>]
            n += y.shape[<span class="hljs-number">0</span>]
        
        <span class="hljs-keyword">try</span>:
            perplexity = math.exp(l_sum / n)
        <span class="hljs-keyword">except</span> OverflowError:
            perplexity = <span class="hljs-built_in">float</span>(<span class="hljs-string">&#x27;inf&#x27;</span>)
        <span class="hljs-keyword">if</span> (epoch + <span class="hljs-number">1</span>) % pred_period == <span class="hljs-number">0</span>:
            print(<span class="hljs-string">&#x27;epoch %d, perplexity %f, time %.2f sec&#x27;</span> % (
                epoch + <span class="hljs-number">1</span>, perplexity, time.time() - start))
            <span class="hljs-keyword">for</span> prefix <span class="hljs-keyword">in</span> prefixes:
                print(<span class="hljs-string">&#x27; -&#x27;</span>, predict_rnn_pytorch(
                    prefix, pred_len, model, vocab_size, device, idx_to_char,
                    char_to_idx))
</code></pre>


            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">神经网络</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/torch/">torch</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://zh.wikipedia.org/wiki/Wikipedia:CC_BY-SA_3.0%E5%8D%8F%E8%AE%AE%E6%96%87%E6%9C%AC" rel="nofollow noopener noopener">CC BY-SA 3.0协议</a> 。转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/posts/439d623b.html">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">计网 Chapter1 网络体系结构</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/posts/8a630470.html">
                        <span class="hidden-mobile"></span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
              <!-- Comments -->
              <article class="comments" id="comments">
                
                
  <div id="vcomments"></div>
  <script type="text/javascript">
    function loadValine() {
      addScript('https://cdn.staticfile.org/valine/1.4.14/Valine.min.js', function () {
        new Valine({
          el: "#vcomments",
          app_id: "a8kpr4nVvMhN2duDaznljFcW-gzGzoHsz",
          app_key: "Qj9gggkYd7RhSSxinWCvCCMk",
          placeholder: "Write a Comment O(∩_∩)O~～",
          path: window.location.pathname,
          avatar: "monsterid",
          meta: ["nick","mail"],
          pageSize: "10",
          lang: "zh-CN",
          highlight: false,
          recordIP: false,
          serverURLs: "",
          emojiCDN: 'https://valinecdn.bili33.top/', 
    // 表情title和图片映射
    emojiMaps: {
      "QQ1": "QQ/aini.gif",
      "QQ2": "QQ/aixin.gif",
      "QQ3": "QQ/aoman.gif",
      "QQ4": "QQ/baiyan.gif",
      "QQ5": "QQ/bangbangtang.gif",
      "QQ6": "QQ/baojin.gif",
      "QQ7": "QQ/baoquan.gif",
      "QQ8": "QQ/bishi.gif",
      "QQ9": "QQ/bizui.gif",
      "QQ11": "QQ/cahan.gif",
      "QQ12": "QQ/caidao.gif",
      "QQ13": "QQ/chi.gif",
      "QQ14": "QQ/ciya.gif",
      "QQ15": "QQ/dabing.gif",
      "QQ16": "QQ/daku.gif",
      "QQ17": "QQ/dan.gif",
      "QQ18": "QQ/deyi.gif",
      "QQ19": "QQ/doge.gif",
      "QQ20": "QQ/fadai.gif",
      "QQ21": "QQ/fanu.gif",
      "QQ22": "QQ/fendou.gif",
      "QQ23": "QQ/ganga.gif",
      "QQ24": "QQ/gouyin.gif",
      "QQ25": "QQ/guzhang.gif",
      "QQ26": "QQ/haixiu.gif",
      "QQ27": "QQ/hanxiao.gif",
      "QQ28": "QQ/haobang.gif",
      "QQ29": "QQ/haqian.gif",
      "QQ30": "QQ/hecai.gif",
      "QQ31": "QQ/hexie.gif",
      "QQ32": "QQ/huaixiao.gif",
      "QQ33": "QQ/jie.gif",
      "QQ34": "QQ/jingkong.gif",
      "QQ35": "QQ/jingxi.gif",
      "QQ36": "QQ/jingya.gif",
      "QQ37": "QQ/juhua.gif",
      "QQ38": "QQ/keai.gif",
      "QQ39": "QQ/kelian.gif",
      "QQ40": "QQ/koubi.gif",
      "QQ41": "QQ/ku.gif",
      "QQ42": "QQ/kuaikule.gif",
      "QQ43": "QQ/kulou.gif",
      "QQ44": "QQ/kun.gif",
      "QQ45": "QQ/lanqiu.gif",
      "QQ46": "QQ/leiben.gif",
      "QQ47": "QQ/lenghan.gif",
      "QQ48": "QQ/liuhan.gif",
      "QQ49": "QQ/liulei.gif",
      "QQ50": "QQ/nanguo.gif",
      "QQ51": "QQ/OK.gif",
      "QQ52": "QQ/penxue.gif",
      "QQ53": "QQ/piezui.gif",
      "QQ54": "QQ/pijiu.gif",
      "QQ55": "QQ/qiang.gif",
      "QQ56": "QQ/qiaoda.gif",
      "QQ57": "QQ/qinqin.gif",
      "QQ58": "QQ/qiudale.gif",
      "QQ59": "QQ/quantou.gif",
      "QQ60": "QQ/saorao.gif",
      "bilibili22332": "bilibili2233/[2233娘_卖萌].png",
      "bilibili22333": "bilibili2233/[2233娘_吃惊].png",
      "bilibili22334": "bilibili2233/[2233娘_吐魂].png",
      "bilibili22335": "bilibili2233/[2233娘_喝水].png",
      "bilibili22336": "bilibili2233/[2233娘_困惑].png",
      "bilibili22337": "bilibili2233/[2233娘_大哭].png",
      "bilibili22338": "bilibili2233/[2233娘_大笑].png",
      "bilibili22339": "bilibili2233/[2233娘_委屈].png",
      "bilibili223310": "bilibili2233/[2233娘_怒].png",
      "bilibili223311": "bilibili2233/[2233娘_无言].png",
      "bilibili223312": "bilibili2233/[2233娘_汗].png",
      "bilibili223313": "bilibili2233/[2233娘_疑问].png",
      "bilibili223314": "bilibili2233/[2233娘_第一].png",
      "bilibili223315": "bilibili2233/[2233娘_耶].png",
      "bilibili223316": "bilibili2233/[2233娘_郁闷].png",
      "Yurui-Neko1": "Yurui-Neko/001.png",
      "Yurui-Neko2": "Yurui-Neko/002.png",
      "Yurui-Neko3": "Yurui-Neko/003.png",
      "Yurui-Neko4": "Yurui-Neko/004.png",
      "Yurui-Neko5": "Yurui-Neko/005.png",
      "Yurui-Neko6": "Yurui-Neko/006.png",
      "Yurui-Neko7": "Yurui-Neko/007.png",
      "Yurui-Neko8": "Yurui-Neko/008.png",
      "Yurui-Neko9": "Yurui-Neko/009.png",
      "Yurui-Neko10": "Yurui-Neko/010.png",
      "Yurui-Neko11": "Yurui-Neko/011.png",
      "Yurui-Neko12": "Yurui-Neko/012.png",
      "Yurui-Neko13": "Yurui-Neko/013.png",
      "Yurui-Neko14": "Yurui-Neko/014.png",
      "Yurui-Neko15": "Yurui-Neko/015.png",
      "Yurui-Neko16": "Yurui-Neko/016.png",
      "Yurui-Neko17": "Yurui-Neko/017.png",
      "Yurui-Neko18": "Yurui-Neko/018.png",
      "Yurui-Neko19": "Yurui-Neko/019.png",
      "Yurui-Neko20": "Yurui-Neko/020.png",
      "Yurui-Neko21": "Yurui-Neko/021.png",
      "Yurui-Neko22": "Yurui-Neko/022.png",
      "Yurui-Neko23": "Yurui-Neko/023.png",
      "Yurui-Neko24": "Yurui-Neko/024.png",
      "Yurui-Neko25": "Yurui-Neko/025.png",
      "Yurui-Neko26": "Yurui-Neko/026.png",
      "Yurui-Neko27": "Yurui-Neko/027.png",
      "Yurui-Neko28": "Yurui-Neko/028.png",
      "Yurui-Neko29": "Yurui-Neko/029.png",
      "Yurui-Neko30": "Yurui-Neko/030.png",
      "Yurui-Neko31": "Yurui-Neko/031.png",
      "Yurui-Neko32": "Yurui-Neko/032.png",
      "Yurui-Neko33": "Yurui-Neko/033.png",
      "Yurui-Neko34": "Yurui-Neko/034.png",
      "Yurui-Neko35": "Yurui-Neko/035.png",
      "Yurui-Neko36": "Yurui-Neko/036.png",
      "Yurui-Neko37": "Yurui-Neko/037.png",
      "Yurui-Neko38": "Yurui-Neko/038.png",
      "Yurui-Neko39": "Yurui-Neko/039.png",
      "Yurui-Neko40": "Yurui-Neko/040.png"
        // ... 更多表情
    }
        });
      });
    }
    waitElementVisible('vcomments', loadValine);
  </script>
  <style>
    .v[data-class=v] .veditor {
        background-image: url(https://www-1259766423.cos.ap-beijing-fsi.myqcloud.com/Picgo/c_girl.gif);
        background-size: contain;
        background-repeat: no-repeat;
        background-position: right;
    }
    </style>
    
  <noscript>Please enable JavaScript to view the <a target="_blank" href="https://valine.js.org" rel="nofollow noopener noopener">comments
      powered by Valine.</a></noscript>


              </article>
            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;TOC</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  
  <div class="statistics">
    
    

    
      
        <!-- LeanCloud 统计PV -->
        <span id="leancloud-site-pv-container" style="display: none">
            总访问量 
            <span id="leancloud-site-pv"></span>
             次
          </span>
      
      
        <!-- LeanCloud 统计UV -->
        <span id="leancloud-site-uv-container" style="display: none">
            总访客数 
            <span id="leancloud-site-uv"></span>
             人
          </span>
      

    
  </div>


  

  
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/main.js" ></script>

<!-- Plugins -->


  
    
      <script  src="/js/lazyload.js" ></script>
    
  



  



  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>



  <script defer>
  (function () {
    // 查询存储的记录
    function getRecord(Counter, target) {
      return new Promise(function (resolve, reject) {
        Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({target})))
          .then(resp => resp.json())
          .then(({results, code, error}) => {
            if (code === 401) {
              throw error;
            }
            if (results && results.length > 0) {
              var record = results[0];
              resolve(record);
            } else {
              Counter('post', '/classes/Counter', {target, time: 0})
                .then(resp => resp.json())
                .then((record, error) => {
                  if (error) {
                    throw error;
                  }
                  resolve(record);
                }).catch(error => {
                console.error('Failed to create', error);
                reject(error);
              });
            }
          }).catch((error) => {
          console.error('LeanCloud Counter Error:', error);
          reject(error);
        });
      })
    }

    // 发起自增请求
    function increment(Counter, incrArr) {
      return new Promise(function (resolve, reject) {
        Counter('post', '/batch', {
          "requests": incrArr
        }).then((res) => {
          res = res.json();
          if (res.error) {
            throw res.error;
          }
          resolve(res);
        }).catch((error) => {
          console.error('Failed to save visitor count', error);
          reject(error);
        });
      });
    }

    // 构建自增请求体
    function buildIncrement(objectId) {
      return {
        "method": "PUT",
        "path": `/1.1/classes/Counter/${ objectId }`,
        "body": {
          "time": {
            '__op': 'Increment',
            'amount': 1
          }
        }
      }
    }

    // 校验是否为有效的 UV
    function validUV() {
      var key = 'LeanCloud_UV_Flag';
      var flag = localStorage.getItem(key);
      if (flag) {
        // 距离标记小于 24 小时则不计为 UV
        if (new Date().getTime() - parseInt(flag) <= 86400000) {
          return false;
        }
      }
      localStorage.setItem(key, new Date().getTime().toString());
      return true;
    }

    function addCount(Counter) {
      var enableIncr = 'true' === 'true' && window.location.hostname !== 'localhost';
      var getterArr = [];
      var incrArr = [];

      // 请求 PV 并自增
      var pvCtn = document.querySelector('#leancloud-site-pv-container');
      if (pvCtn || enableIncr) {
        var pvGetter = getRecord(Counter, 'site-pv').then((record) => {
          incrArr.push(buildIncrement(record.objectId))
          var ele = document.querySelector('#leancloud-site-pv');
          if (ele) {
            ele.innerText = record.time + 1;
            if (pvCtn) {
              pvCtn.style.display = 'inline';
            }
          }
        });
        getterArr.push(pvGetter);
      }

      // 请求 UV 并自增
      var uvCtn = document.querySelector('#leancloud-site-uv-container');
      if (uvCtn || enableIncr) {
        var uvGetter = getRecord(Counter, 'site-uv').then((record) => {
          var vuv = validUV();
          vuv && incrArr.push(buildIncrement(record.objectId))
          var ele = document.querySelector('#leancloud-site-uv');
          if (ele) {
            ele.innerText = record.time + (vuv ? 1 : 0);
            if (uvCtn) {
              uvCtn.style.display = 'inline';
            }
          }
        });
        getterArr.push(uvGetter);
      }

      // 如果是文章，请求文章的浏览数，并自增
      if ('true' === 'true') {
        var viewCtn = document.querySelector('#leancloud-post-views-container');
        if (viewCtn || enableIncr) {
          var target = decodeURI('/posts/cb6a52c.html');
          var viewGetter = getRecord(Counter, target).then((record) => {
            incrArr.push(buildIncrement(record.objectId))
            if (viewCtn) {
              var ele = document.querySelector('#leancloud-post-views');
              if (ele) {
                ele.innerText = (record.time || 0) + 1;
                viewCtn.style.display = 'inline';
              }
            }
          });
          getterArr.push(viewGetter);
        }
      }

      // 如果启动计数自增，批量发起自增请求
      if (enableIncr) {
        Promise.all(getterArr).then(() => {
          incrArr.length > 0 && increment(Counter, incrArr);
        })
      }
    }

    var app_id = 'a8kpr4nVvMhN2duDaznljFcW-gzGzoHsz'
    var app_key = 'Qj9gggkYd7RhSSxinWCvCCMk'
    var server_url = ''

    function fetchData(api_server) {
      var Counter = (method, url, data) => {
        return fetch(`${ api_server }/1.1${ url }`, {
          method,
          headers: {
            'X-LC-Id': app_id,
            'X-LC-Key': app_key,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };

      addCount(Counter);
    }

    var api_server = app_id.slice(-9) !== '-MdYXbMMI' ? server_url : `https://${ app_id.slice(0, 8).toLowerCase() }.api.lncldglobal.com`;

    if (api_server) {
      fetchData(api_server);
    } else {
      fetch('https://app-router.leancloud.cn/2/route?appId=' + app_id)
        .then(resp => resp.json())
        .then(({api_server}) => {
          fetchData('https://' + api_server);
        });
    }
  })();
</script>






  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: '#post-body',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "LSTM -Pytorch实现&解构&nbsp;",
      ],
      cursorChar: "🐟",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>












  

  
    <!-- Google Analytics -->
    <script defer>
      window.ga = window.ga || function () { (ga.q = ga.q || []).push(arguments) };
      ga.l = +new Date;
      ga('create', 'UA-166912137-1', 'auto');
      ga('send', 'pageview');
    </script>
    <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  

  

  

  





<!-- hexo injector body_end start -->
  <div id="aplayer"></div>
  <link defer rel="stylesheet" href="https://cdn.staticfile.org/aplayer/1.10.1/APlayer.min.css" />
  <script src="https://cdn.staticfile.org/aplayer/1.10.1/APlayer.min.js"></script>
  <script defer src="/js/aplayer.js"></script>
<!-- hexo injector body_end end --><script src="https://cdn.jsdelivr.net/npm/live2d-widget@^3.1.3/lib/L2Dwidget.min.js"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"https://cdn.jsdelivr.net/gh/cher112/live2d@master/live2d_models/Yamato/Yamato.model.json"},"mobile":{"show":false},"display":{"superSample":2,"position":"right","vOffset":-20,"hOffset":40,"width":200,"height":300},"react":{"opacity":0.8},"log":false});</script></body>
</html>
